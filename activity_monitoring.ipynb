{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (PyTorch)\n",
    "\n",
    "1. Load Datset (Training/Testing)\n",
    "2. Format Dataset\n",
    "3. Class for Dataset/Dataloader\n",
    "4. Class for Neural Network (NN)\n",
    "5. Training\n",
    "    i. defining Training loop/ numOfEpochs\n",
    "    ii. Dataload to NN\n",
    "    iii. Forward Propagation\n",
    "    iv. Loss computation\n",
    "    v. Backpropagation/gradient computation\n",
    "    vi. update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "6Hi5yYVvbRC_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "#import os\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "zMBlqHy_eMgx"
   },
   "outputs": [],
   "source": [
    "#path = \"/content/sample_data/activity_monitoring/\"\n",
    "#path = \"/content/sample_data/\"\n",
    "path = 'D:\\\\University\\\\Machine learning\\\\project\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "7N7kF30zeRjZ"
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_msAcc = np.load(path+\"training\\\\\"+\"trainMSAccelerometer.npy\")\n",
    "train_msGyro = np.load(path+\"training\\\\\"+\"trainMSGyroscope.npy\")\n",
    "train_Acc = np.load(path+\"training\\\\\"+\"trainAccelerometer.npy\")\n",
    "train_Grav = np.load(path+\"training\\\\\"+\"trainGravity.npy\")\n",
    "train_jinAcc = np.load(path+\"training\\\\\"+\"trainJinsAccelerometer.npy\")\n",
    "train_jinGyro = np.load(path+\"training\\\\\"+\"trainJinsGyroscope.npy\")\n",
    "train_liAcc = np.load(path+\"training\\\\\"+\"trainLinearAcceleration.npy\")\n",
    "train_Mag = np.load(path+\"training\\\\\"+\"trainMagnetometer.npy\")\n",
    "train_Gyro = np.load(path+\"training\\\\\"+\"trainGyroscope.npy\")\n",
    "train_labels = np.load(path+\"training\\\\\"+\"trainlabels.npy\")\n",
    "\n",
    "test_msAcc = np.load(path+\"testing\\\\\"+\"testMSAccelerometer.npy\")\n",
    "test_msGyro = np.load(path+\"testing\\\\\"+\"testMSGyroscope.npy\")\n",
    "test_Acc = np.load(path+\"testing\\\\\"+\"testAccelerometer.npy\")\n",
    "test_Grav = np.load(path+\"testing\\\\\"+\"testGravity.npy\")\n",
    "test_jinAcc = np.load(path+\"testing\\\\\"+\"testJinsAccelerometer.npy\")\n",
    "test_jinGyro = np.load(path+\"testing\\\\\"+\"testJinsGyroscope.npy\")\n",
    "test_liAcc = np.load(path+\"testing\\\\\"+\"testLinearAcceleration.npy\")\n",
    "test_Mag = np.load(path+\"testing\\\\\"+\"testMagnetometer.npy\")\n",
    "test_Gyro = np.load(path+\"testing\\\\\"+\"testGyroscope.npy\")\n",
    "test_labels = np.load(path+\"testing\\\\\"+\"testlabels.npy\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "cRsGy1VOeUmI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 268, 3)\n",
      "(2284, 268, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 80, 3)\n",
      "(2284, 80, 3)\n",
      "(2284, 800, 3)\n",
      "(2284, 200, 3)\n",
      "(2284, 800, 3)\n",
      "(2284,)\n",
      "(2288, 268, 3)\n",
      "(2288, 268, 3)\n",
      "(2288, 80, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 80, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 200, 3)\n",
      "(2288, 800, 3)\n",
      "(2288, 800, 3)\n",
      "(2288,)\n"
     ]
    }
   ],
   "source": [
    "print(train_msAcc.shape)\n",
    "print(train_msGyro.shape)\n",
    "print(train_Acc.shape)\n",
    "print(train_Grav.shape)\n",
    "print(train_jinAcc.shape)\n",
    "print(train_jinGyro.shape)\n",
    "print(train_liAcc.shape)\n",
    "print(train_Mag.shape)\n",
    "print(train_Gyro.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_msAcc.shape)\n",
    "print(test_msGyro.shape)\n",
    "print(test_jinAcc.shape)\n",
    "print(test_Grav.shape)\n",
    "print(test_jinGyro.shape)\n",
    "print(test_liAcc.shape)\n",
    "print(test_Mag.shape)\n",
    "print(test_Gyro.shape)\n",
    "print(test_Acc.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "Goo-YhX4b2Ap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2288, 268, 3)\n",
      "(2284, 268, 3)\n",
      "(2284, 268, 3)\n",
      "(2288, 268, 3)\n",
      "(2288, 268, 3)\n",
      "msAcc: (2284, 804)\n",
      "msGyro (2284, 804)\n",
      "(2284, 2400)\n",
      "(2284, 2400)\n",
      "(2284, 240)\n",
      "(2284, 240)\n",
      "(2284, 2400)\n",
      "(2284, 600)\n",
      "(2284, 2400)\n",
      "(2284,)\n"
     ]
    }
   ],
   "source": [
    "#for CNN\n",
    "# train_msAcc Gyrorain_msAcc.transpose((0,2,1))\n",
    "# test_estc = test_msAcc.transpose((0,2,1))\n",
    "print(test_msGyro.shape)\n",
    "# train_msGyro = train_msGyro.transpose((0,2,1))\n",
    "# test_msGyro = test_msGyro.transpose((0,2,1))\n",
    "\n",
    "print(train_msAcc.shape) #87,3,268\n",
    "print(train_msGyro.shape)\n",
    "print(test_msAcc.shape)\n",
    "print(test_msGyro.shape)\n",
    "\n",
    "#for linear NN\n",
    "train_msAcc = np.reshape(train_msAcc, (train_msAcc.shape[0],train_msAcc.shape[1]*train_msAcc.shape[2]))\n",
    "train_msGyro = np.reshape(train_msGyro, (train_msGyro.shape[0],train_msGyro.shape[1]*train_msGyro.shape[2]))\n",
    "train_Acc = np.reshape(train_Acc, (train_Acc.shape[0],train_Acc.shape[1]*train_Acc.shape[2]))\n",
    "train_Grav = np.reshape(train_Grav, (train_Grav.shape[0],train_Grav.shape[1]*train_Grav.shape[2]))\n",
    "train_jinAcc = np.reshape(train_jinAcc, (train_jinAcc.shape[0],train_jinAcc.shape[1]*train_jinAcc.shape[2]))\n",
    "train_jinGyro = np.reshape(train_jinGyro, (train_jinGyro.shape[0],train_jinGyro.shape[1]*train_jinGyro.shape[2]))\n",
    "train_liAcc = np.reshape(train_liAcc, (train_liAcc.shape[0],train_liAcc.shape[1]*train_liAcc.shape[2]))\n",
    "train_Mag = np.reshape(train_Mag, (train_Mag.shape[0],train_Mag.shape[1]*train_Mag.shape[2]))\n",
    "train_Gyro = np.reshape(train_Gyro, (train_Gyro.shape[0],train_Gyro.shape[1]*train_Gyro.shape[2]))\n",
    "\n",
    "test_msAcc = np.reshape(test_msAcc, (test_msAcc.shape[0],test_msAcc.shape[1]*test_msAcc.shape[2]))\n",
    "test_msGyro = np.reshape(test_msGyro, (test_msGyro.shape[0],test_msGyro.shape[1]*test_msGyro.shape[2]))\n",
    "test_Acc = np.reshape(test_Acc, (test_Acc.shape[0],test_Acc.shape[1]*test_Acc.shape[2]))\n",
    "test_Grav = np.reshape(test_Grav, (test_Grav.shape[0],test_Grav.shape[1]*test_Grav.shape[2]))\n",
    "test_jinAcc = np.reshape(test_jinAcc, (test_jinAcc.shape[0],test_jinAcc.shape[1]*test_jinAcc.shape[2]))\n",
    "test_jinGyro = np.reshape(test_jinGyro, (test_jinGyro.shape[0],test_jinGyro.shape[1]*test_jinGyro.shape[2]))\n",
    "test_liAcc = np.reshape(test_liAcc, (test_liAcc.shape[0],test_liAcc.shape[1]*test_liAcc.shape[2]))\n",
    "test_Mag = np.reshape(test_Mag, (test_Mag.shape[0],test_Mag.shape[1]*test_Mag.shape[2]))\n",
    "test_Gyro = np.reshape(test_Gyro, (test_Gyro.shape[0],test_Gyro.shape[1]*test_Gyro.shape[2]))\n",
    "\n",
    "print(f\"msAcc: {train_msAcc.shape}\")\n",
    "print(f\"msGyro {train_msGyro.shape}\")\n",
    "print(train_Acc.shape)\n",
    "print(train_Grav.shape)\n",
    "print(train_jinAcc.shape)\n",
    "print(train_jinGyro.shape)\n",
    "print(train_liAcc.shape)\n",
    "print(train_Mag.shape)\n",
    "print(train_Gyro.shape)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47 47 22 ... 33 29 28]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[17 10 34 ... 29 34 10]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "MDnNnPhCjRvg"
   },
   "outputs": [],
   "source": [
    "#cogAge class to hold data\n",
    "class CogAgeDataset(Dataset):\n",
    "    def __init__(self, cd_msAcc, cd_msGyro, cd_Acc, cd_Grav, cd_jinAcc, cd_jinGyro, cd_liAcc, cd_Mag, cd_Gyro, cd_labels ):\n",
    "        self.msAcc = cd_msAcc\n",
    "        self.msGyro = cd_msGyro\n",
    "        self.cd_Gyro = cd_Gyro\n",
    "        self.cd_Acc = cd_Acc\n",
    "        self.cd_Grav = cd_Grav\n",
    "        self.cd_jinAcc = cd_jinAcc\n",
    "        self.cd_jinGyro = cd_jinGyro\n",
    "        self.cd_liAcc = cd_liAcc\n",
    "        self.cd_Mag = cd_Mag\n",
    "        self.labels = cd_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.msAcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.msAcc[index], self.msGyro[index], self.cd_Acc[index], self.cd_Grav[index], self.cd_jinAcc[index], self.cd_jinGyro[index], self.cd_liAcc[index], self.cd_Mag[index], self.cd_Gyro[index], self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "Vdp0QPJnTjLo"
   },
   "outputs": [],
   "source": [
    "# activity monitoring\n",
    "class ActivityMonitoring_FC(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ActivityMonitoring_FC, self).__init__()\n",
    "        \n",
    "        self.fc11 = nn.Linear(804 , 1024)  #msacc # flatten inpu dimension\n",
    "        self.fc12 = nn.Linear(804 , 1024) #msgyro\n",
    "        self.fc13 = nn.Linear(2400 , 1024)  #acc # flatten inpu dimension\n",
    "        self.fc14 = nn.Linear(2400 , 1024) #grav\n",
    "        self.fc15 = nn.Linear(240 , 1024)  #jinAcc # flatten inpu dimension\n",
    "        self.fc16 = nn.Linear(240 , 1024) #jinGyro\n",
    "        self.fc17 = nn.Linear(2400 , 1024)  #liAcc # flatten inpu dimension\n",
    "        self.fc18 = nn.Linear(600 , 1024) #mag\n",
    "        self.fc19 = nn.Linear(2400 , 1024)  #gyro # flatten inpu dimension \n",
    "        \n",
    "        self.fc21 = nn.Linear(1024 , 512)\n",
    "        self.fc22 = nn.Linear(1024 , 512)\n",
    "        self.fc23 = nn.Linear(1024 , 512)  #acc # flatten inpu dimension\n",
    "        self.fc24 = nn.Linear(1024 , 512) #grav\n",
    "        self.fc25 = nn.Linear(1024 , 512)  #jinAcc # flatten inpu dimension\n",
    "        self.fc26 = nn.Linear(1024 , 512) #jinGyro\n",
    "        self.fc27 = nn.Linear(1024 , 512)  #liAcc # flatten inpu dimension\n",
    "        self.fc28 = nn.Linear(1024 , 512) #mag\n",
    "        self.fc29 = nn.Linear(1024 , 512)  #gyro # flatten inpu dimension \n",
    "        \n",
    "        self.fc3 = nn.Linear(4608 , 2304)\n",
    "        self.fc4 = nn.Linear(2304 , 1152)\n",
    "        # self.fc5 = nn.Linear(1152 , 576)\n",
    "        # self.fc6 = nn.Linear(576 , 288)\n",
    "\n",
    "        # self.output = nn.Linear(288 , 55)\n",
    "        self.output = nn.Linear(1152 , 55)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, msAcc, msGyro, Acc, Grav, jinAcc, jinGyro, liAcc, Mag, Gyro):\n",
    "\n",
    "        # print(\"msAcc input shape:\", msAcc.shape)\n",
    "        msAcc = self.fc11(msAcc) #z-vector\n",
    "        msAcc = F.relu(msAcc)\n",
    "        msAcc = self.fc21(msAcc)\n",
    "        msAcc = F.relu(msAcc)\n",
    "\n",
    "        # print(\"msAcc.shape:\", msAcc.shape)\n",
    "\n",
    "\n",
    "        # print(\"msGyro input shape:\", msGyro.shape)\n",
    "        msGyro = self.fc12(msGyro)\n",
    "        msGyro = F.relu(msGyro)\n",
    "        msGyro = self.fc22(msGyro)\n",
    "        msGyro = F.relu(msGyro)\n",
    "\n",
    "        # print(\"msGyro.shape:\", msGyro.shape)\n",
    "\n",
    "        # print(\"Acc input shape:\", Acc.shape)\n",
    "        Acc = self.fc13(Acc)\n",
    "        Acc = F.relu(Acc)\n",
    "        Acc = self.fc23(Acc)\n",
    "        Acc = F.relu(Acc)\n",
    "\n",
    "        # print(\"Acc.shape:\", Acc.shape)\n",
    "        # print(\"input shape:\", Grav.shape)\n",
    "        Grav = self.fc14(Grav)\n",
    "        Grav = F.relu(Grav)\n",
    "        Grav = self.fc24(Grav)\n",
    "        Grav = F.relu(Grav)\n",
    "\n",
    "        # print(\"msGyro.shape:\", Grav.shape)\n",
    "        # print(\"input shape:\", jinAcc.shape)\n",
    "        jinAcc = self.fc15(jinAcc)\n",
    "        jinAcc = F.relu(jinAcc)\n",
    "        jinAcc = self.fc25(jinAcc)\n",
    "        jinAcc = F.relu(jinAcc)\n",
    "\n",
    "        # print(\"msGyro.shape:\", jinAcc.shape)\n",
    "        # print(\"input shape:\", msGyro.shape)\n",
    "        jinGyro = self.fc16(jinGyro)\n",
    "        jinGyro = F.relu(jinGyro)\n",
    "        jinGyro = self.fc26(jinGyro)\n",
    "        jinGyro = F.relu(jinGyro)\n",
    "\n",
    "        # print(\"msGyro.shape:\", msGyro.shape)\n",
    "        # print(\"input shape:\", msGyro.shape)\n",
    "        liAcc = self.fc17(liAcc)\n",
    "        liAcc = F.relu(liAcc)\n",
    "        liAcc = self.fc27(liAcc)\n",
    "        liAcc = F.relu(liAcc)\n",
    "\n",
    "        # print(\"msGyro.shape:\", msGyro.shape)\n",
    "        # print(\"input shape:\", msGyro.shape)\n",
    "        Mag = self.fc18(Mag)\n",
    "        Mag = F.relu(Mag)\n",
    "        Mag = self.fc28(Mag)\n",
    "        Mag = F.relu(Mag)\n",
    "\n",
    "        # print(\"msGyro.shape:\", msGyro.shape)\n",
    "        \n",
    "        # print(\"input shape:\", msGyro.shape)\n",
    "        Gyro = self.fc19(Gyro)\n",
    "        Gyro = F.relu(Gyro)\n",
    "        Gyro = self.fc29(Gyro)\n",
    "        Gyro = F.relu(Gyro)\n",
    "\n",
    "        # print(\"msGyro.shape:\", msGyro.shape)\n",
    "        \n",
    "        joint_channels = torch.cat(( msAcc, msGyro, Acc, Grav, jinAcc, jinGyro, liAcc, Mag, Gyro), 1)\n",
    "        # print(\"joint_channels.shape after concat:\", joint_channels.shape)\n",
    "        act = F.relu(self.fc3(joint_channels))\n",
    "        # print(\"act shape after fc3: \", act.shape)\n",
    "        act = F.relu(self.fc4(act))\n",
    "        # act = F.relu(self.fc5(act))\n",
    "        act = self.dropout1(act)\n",
    "        # act = F.relu(self.fc6(act))\n",
    "        # print(\"act shape after fc4: \", act.shape)\n",
    "        act = self.dropout2(act)\n",
    "        act_out = self.output(act)\n",
    "        # print(\"act_out shape after output layer: \", act_out.shape)\n",
    "\n",
    "        return act_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "Y1W1dFvNYmb4"
   },
   "outputs": [],
   "source": [
    "#defining loss_fn, optimizer, model\n",
    "lr = 0.01\n",
    "act_model = ActivityMonitoring_FC()\n",
    "optimizer_act = optim.Adam(act_model.parameters(), lr=lr) #for state activities\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "INUGoMCecJ3R"
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_dataset = CogAgeDataset(train_msAcc, train_msGyro,train_Acc,train_Grav,train_jinAcc,train_jinGyro,train_liAcc,train_Mag,train_Gyro, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = CogAgeDataset(test_msAcc, test_msGyro,test_Acc,test_Grav,test_jinAcc,test_jinGyro,test_liAcc,test_Mag,test_Gyro, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "jeI2-b7AYb8R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, Loss: 0 ,  3.9030890464782715\n",
      "Epoch, Loss: 0 ,  25614.69921875\n",
      "Epoch, Loss: 0 ,  192.33340454101562\n",
      "Epoch, Loss: 0 ,  136.64605712890625\n",
      "Epoch, Loss: 0 ,  162.241455078125\n",
      "Epoch, Loss: 0 ,  82.41606140136719\n",
      "Epoch, Loss: 0 ,  492.99713134765625\n",
      "Epoch, Loss: 0 ,  201.8343505859375\n",
      "Epoch, Loss: 0 ,  166.58395385742188\n",
      "Epoch, Loss: 0 ,  105.84175109863281\n",
      "Epoch, Loss: 0 ,  668.7124633789062\n",
      "Epoch, Loss: 0 ,  111.78501892089844\n",
      "Epoch, Loss: 0 ,  103.82469177246094\n",
      "Epoch, Loss: 0 ,  148.82534790039062\n",
      "Epoch, Loss: 0 ,  135.23855590820312\n",
      "Epoch, Loss: 0 ,  111.2412109375\n",
      "Epoch, Loss: 0 ,  93.84623718261719\n",
      "Epoch, Loss: 0 ,  73.2242431640625\n",
      "Epoch, Loss: 0 ,  79.16683959960938\n",
      "Epoch, Loss: 0 ,  71.73094940185547\n",
      "Epoch, Loss: 0 ,  106.4382553100586\n",
      "Epoch, Loss: 0 ,  108.60919189453125\n",
      "Epoch, Loss: 0 ,  44.06578063964844\n",
      "Epoch, Loss: 0 ,  42.920772552490234\n",
      "Epoch, Loss: 0 ,  19.23505210876465\n",
      "Epoch, Loss: 0 ,  21.78750991821289\n",
      "Epoch, Loss: 0 ,  19.755746841430664\n",
      "Epoch, Loss: 0 ,  10.815817832946777\n",
      "Epoch, Loss: 0 ,  13.605415344238281\n",
      "Epoch, Loss: 0 ,  9.595827102661133\n",
      "Epoch, Loss: 0 ,  4.019744396209717\n",
      "Epoch, Loss: 0 ,  4.135603427886963\n",
      "Epoch, Loss: 0 ,  9.273996353149414\n",
      "Epoch, Loss: 0 ,  10.333035469055176\n",
      "Epoch, Loss: 0 ,  11.334012031555176\n",
      "Epoch, Loss: 0 ,  4.658007621765137\n",
      "Epoch, Loss: 0 ,  6.587255001068115\n",
      "Epoch, Loss: 0 ,  5.653772830963135\n",
      "Epoch, Loss: 0 ,  4.019954681396484\n",
      "Epoch, Loss: 0 ,  3.6336891651153564\n",
      "Epoch, Loss: 0 ,  4.0255327224731445\n",
      "Epoch, Loss: 0 ,  6.933080196380615\n",
      "Epoch, Loss: 0 ,  4.024263381958008\n",
      "Epoch, Loss: 0 ,  6.094112396240234\n",
      "Epoch, Loss: 0 ,  4.011395454406738\n",
      "Epoch, Loss: 0 ,  4.028957843780518\n",
      "Epoch, Loss: 0 ,  4.000121593475342\n",
      "Epoch, Loss: 0 ,  4.002662181854248\n",
      "Epoch, Loss: 0 ,  4.012642860412598\n",
      "Epoch, Loss: 0 ,  4.020581245422363\n",
      "Epoch, Loss: 0 ,  4.005588531494141\n",
      "Epoch, Loss: 0 ,  3.9913856983184814\n",
      "Epoch, Loss: 0 ,  4.012687683105469\n",
      "Epoch, Loss: 0 ,  4.014927864074707\n",
      "Epoch, Loss: 0 ,  4.003422737121582\n",
      "Epoch, Loss: 0 ,  5.980380058288574\n",
      "Epoch, Loss: 0 ,  3.9972305297851562\n",
      "Epoch, Loss: 0 ,  4.026155471801758\n",
      "Epoch, Loss: 0 ,  4.008347511291504\n",
      "Epoch, Loss: 0 ,  4.015783309936523\n",
      "Epoch, Loss: 0 ,  4.026838779449463\n",
      "Epoch, Loss: 0 ,  17.03415298461914\n",
      "Epoch, Loss: 0 ,  3.9982070922851562\n",
      "Epoch, Loss: 0 ,  3.999886989593506\n",
      "Epoch, Loss: 0 ,  4.011599063873291\n",
      "Epoch, Loss: 0 ,  4.010595798492432\n",
      "Epoch, Loss: 0 ,  3.991727352142334\n",
      "Epoch, Loss: 0 ,  4.01737117767334\n",
      "Epoch, Loss: 0 ,  4.062298774719238\n",
      "Epoch, Loss: 0 ,  3.9808762073516846\n",
      "Epoch, Loss: 0 ,  4.0048322677612305\n",
      "Epoch, Loss: 0 ,  4.017162799835205\n",
      "Epoch, Loss: 0 ,  4.00740385055542\n",
      "Epoch, Loss: 0 ,  4.017068386077881\n",
      "Epoch, Loss: 0 ,  4.006608486175537\n",
      "Epoch, Loss: 0 ,  3.9996986389160156\n",
      "Epoch, Loss: 0 ,  4.017073154449463\n",
      "Epoch, Loss: 0 ,  4.0083088874816895\n",
      "Epoch, Loss: 0 ,  4.005706310272217\n",
      "Epoch, Loss: 0 ,  3.994351625442505\n",
      "Epoch, Loss: 0 ,  4.024600982666016\n",
      "Epoch, Loss: 0 ,  4.014859676361084\n",
      "Epoch, Loss: 0 ,  4.032888889312744\n",
      "Epoch, Loss: 0 ,  4.017433166503906\n",
      "Epoch, Loss: 0 ,  4.045567989349365\n",
      "Epoch, Loss: 0 ,  4.0339274406433105\n",
      "Epoch, Loss: 0 ,  4.021090984344482\n",
      "Epoch, Loss: 0 ,  3.955918073654175\n",
      "Epoch, Loss: 0 ,  7.468770503997803\n",
      "Epoch, Loss: 0 ,  262.113037109375\n",
      "Epoch, Loss: 0 ,  4.0077104568481445\n",
      "Epoch, Loss: 0 ,  3.981539249420166\n",
      "Epoch, Loss: 0 ,  11.18124008178711\n",
      "Epoch, Loss: 0 ,  5.921085357666016\n",
      "Epoch, Loss: 0 ,  5.828239917755127\n",
      "Epoch, Loss: 0 ,  4.008255481719971\n",
      "Epoch, Loss: 0 ,  4.004483699798584\n",
      "Epoch, Loss: 0 ,  3.995163679122925\n",
      "Epoch, Loss: 0 ,  7.6208086013793945\n",
      "Epoch, Loss: 0 ,  4.032391548156738\n",
      "Epoch, Loss: 0 ,  4.044469356536865\n",
      "Epoch, Loss: 0 ,  3.981367826461792\n",
      "Epoch, Loss: 0 ,  4.171239376068115\n",
      "Epoch, Loss: 0 ,  4.008556842803955\n",
      "Epoch, Loss: 0 ,  4.014501571655273\n",
      "Epoch, Loss: 0 ,  4.026313781738281\n",
      "Epoch, Loss: 0 ,  4.054009437561035\n",
      "Epoch, Loss: 0 ,  4.009905815124512\n",
      "Epoch, Loss: 0 ,  4.006331443786621\n",
      "Epoch, Loss: 0 ,  4.022202014923096\n",
      "Epoch, Loss: 0 ,  4.011006832122803\n",
      "Epoch, Loss: 0 ,  4.002310276031494\n",
      "Epoch, Loss: 0 ,  4.0025434494018555\n",
      "Epoch, Loss: 0 ,  4.018187999725342\n",
      "Epoch, Loss: 0 ,  3.997112989425659\n",
      "Epoch, Loss: 0 ,  3.9986915588378906\n",
      "Epoch, Loss: 0 ,  4.015480995178223\n",
      "Epoch, Loss: 0 ,  4.011716842651367\n",
      "Epoch, Loss: 0 ,  4.032831192016602\n",
      "Epoch, Loss: 0 ,  3.990797519683838\n",
      "Epoch, Loss: 0 ,  4.004581928253174\n",
      "Epoch, Loss: 0 ,  4.001206398010254\n",
      "Epoch, Loss: 0 ,  4.028408527374268\n",
      "Epoch, Loss: 0 ,  4.040077209472656\n",
      "Epoch, Loss: 0 ,  3.989345073699951\n",
      "Epoch, Loss: 0 ,  3.979779005050659\n",
      "Epoch, Loss: 0 ,  4.022548198699951\n",
      "Epoch, Loss: 0 ,  4.028932094573975\n",
      "Epoch, Loss: 0 ,  4.034301280975342\n",
      "Epoch, Loss: 0 ,  3.9952614307403564\n",
      "Epoch, Loss: 0 ,  4.017560005187988\n",
      "Epoch, Loss: 0 ,  4.029857158660889\n",
      "Epoch, Loss: 0 ,  4.004695415496826\n",
      "Epoch, Loss: 0 ,  3.9826042652130127\n",
      "Epoch, Loss: 0 ,  4.040053844451904\n",
      "Epoch, Loss: 0 ,  3.996683120727539\n",
      "Epoch, Loss: 0 ,  4.002211570739746\n",
      "Epoch, Loss: 0 ,  4.015155792236328\n",
      "Epoch, Loss: 0 ,  3.990671157836914\n",
      "Epoch, Loss: 0 ,  4.006636619567871\n",
      "Epoch, Loss: 0 ,  4.001988410949707\n",
      "Epoch, Loss: 0 ,  4.026933670043945\n",
      "Epoch, Loss: 0 ,  4.0147600173950195\n",
      "Epoch, Loss: 0 ,  4.039259910583496\n",
      "Epoch, Loss: 0 ,  3.998755693435669\n",
      "Epoch, Loss: 0 ,  4.020981788635254\n",
      "Epoch, Loss: 0 ,  3.9915127754211426\n",
      "Epoch, Loss: 0 ,  3.985304594039917\n",
      "Epoch, Loss: 0 ,  3.999774932861328\n",
      "Epoch, Loss: 0 ,  4.039247512817383\n",
      "Epoch, Loss: 0 ,  4.033059120178223\n",
      "Epoch, Loss: 0 ,  3.992520570755005\n",
      "Epoch, Loss: 0 ,  4.023089408874512\n",
      "Epoch, Loss: 0 ,  3.981919050216675\n",
      "Epoch, Loss: 0 ,  3.9999427795410156\n",
      "Epoch, Loss: 0 ,  4.001492500305176\n",
      "Epoch, Loss: 0 ,  4.013218879699707\n",
      "Epoch, Loss: 0 ,  3.9855258464813232\n",
      "Epoch, Loss: 0 ,  4.032122611999512\n",
      "Epoch, Loss: 0 ,  4.0168633460998535\n",
      "Epoch, Loss: 0 ,  4.01033878326416\n",
      "Epoch, Loss: 0 ,  3.998563289642334\n",
      "Epoch, Loss: 0 ,  3.987274169921875\n",
      "Epoch, Loss: 0 ,  4.056153297424316\n",
      "Epoch, Loss: 0 ,  4.019513130187988\n",
      "Epoch, Loss: 0 ,  4.023919105529785\n",
      "Epoch, Loss: 0 ,  4.065646171569824\n",
      "Epoch, Loss: 0 ,  3.971698760986328\n",
      "Epoch, Loss: 0 ,  4.021580696105957\n",
      "Epoch, Loss: 0 ,  3.9965953826904297\n",
      "Epoch, Loss: 0 ,  4.054425239562988\n",
      "Epoch, Loss: 0 ,  4.011404514312744\n",
      "Epoch, Loss: 0 ,  3.999119281768799\n",
      "Epoch, Loss: 0 ,  4.03474235534668\n",
      "Epoch, Loss: 0 ,  3.994196653366089\n",
      "Epoch, Loss: 0 ,  4.008300304412842\n",
      "Epoch, Loss: 0 ,  4.038844108581543\n",
      "Epoch, Loss: 0 ,  4.0108747482299805\n",
      "Epoch, Loss: 0 ,  4.028937816619873\n",
      "Epoch, Loss: 0 ,  4.028614044189453\n",
      "Epoch, Loss: 0 ,  4.026629447937012\n",
      "Epoch, Loss: 0 ,  4.0569000244140625\n",
      "Epoch, Loss: 0 ,  4.027905464172363\n",
      "Epoch, Loss: 0 ,  3.9988017082214355\n",
      "Epoch, Loss: 0 ,  4.024706840515137\n",
      "Epoch, Loss: 0 ,  4.018160820007324\n",
      "Epoch, Loss: 0 ,  4.021914482116699\n",
      "Epoch, Loss: 0 ,  3.982537031173706\n",
      "Epoch, Loss: 0 ,  4.047478675842285\n",
      "Epoch, Loss: 0 ,  4.004937171936035\n",
      "Epoch, Loss: 0 ,  4.0105085372924805\n",
      "Epoch, Loss: 0 ,  4.026243686676025\n",
      "Epoch, Loss: 0 ,  3.9926235675811768\n",
      "Epoch, Loss: 0 ,  4.004300594329834\n",
      "Epoch, Loss: 0 ,  3.9920547008514404\n",
      "Epoch, Loss: 0 ,  3.999845027923584\n",
      "Epoch, Loss: 0 ,  3.9944241046905518\n",
      "Epoch, Loss: 0 ,  4.021159648895264\n",
      "Epoch, Loss: 0 ,  4.016749858856201\n",
      "Epoch, Loss: 0 ,  4.0310235023498535\n",
      "Epoch, Loss: 0 ,  4.0023980140686035\n",
      "Epoch, Loss: 0 ,  4.002410411834717\n",
      "Epoch, Loss: 0 ,  3.969965696334839\n",
      "Epoch, Loss: 0 ,  3.979285478591919\n",
      "Epoch, Loss: 0 ,  4.031195163726807\n",
      "Epoch, Loss: 0 ,  4.016762733459473\n",
      "Epoch, Loss: 0 ,  3.9853014945983887\n",
      "Epoch, Loss: 0 ,  4.006582260131836\n",
      "Epoch, Loss: 0 ,  4.002048015594482\n",
      "Epoch, Loss: 0 ,  3.998142957687378\n",
      "Epoch, Loss: 0 ,  3.995443820953369\n",
      "Epoch, Loss: 0 ,  4.0592732429504395\n",
      "Epoch, Loss: 0 ,  4.002378940582275\n",
      "Epoch, Loss: 0 ,  3.9968090057373047\n",
      "Epoch, Loss: 0 ,  4.015460014343262\n",
      "Epoch, Loss: 0 ,  4.031952857971191\n",
      "Epoch, Loss: 0 ,  4.02043342590332\n",
      "Epoch, Loss: 0 ,  4.032169818878174\n",
      "Epoch, Loss: 0 ,  4.020131587982178\n",
      "Epoch, Loss: 0 ,  3.9992427825927734\n",
      "Epoch, Loss: 0 ,  4.039918899536133\n",
      "Epoch, Loss: 0 ,  4.017866611480713\n",
      "Epoch, Loss: 0 ,  3.995173692703247\n",
      "Epoch, Loss: 0 ,  3.993683338165283\n",
      "Epoch, Loss: 0 ,  4.012632846832275\n",
      "Epoch, Loss: 0 ,  4.004084587097168\n",
      "Epoch, Loss: 0 ,  4.002560615539551\n",
      "Epoch, Loss: 0 ,  4.000214099884033\n",
      "Epoch, Loss: 0 ,  3.9780845642089844\n",
      "epoch: 0\n",
      "Training: batch_loss: 132.192, Accuracy: 1.357\n",
      "Epoch, Loss: 1 ,  4.007998466491699\n",
      "Epoch, Loss: 1 ,  3.9862475395202637\n",
      "Epoch, Loss: 1 ,  4.089929580688477\n",
      "Epoch, Loss: 1 ,  3.991180896759033\n",
      "Epoch, Loss: 1 ,  3.991128921508789\n",
      "Epoch, Loss: 1 ,  4.054450511932373\n",
      "Epoch, Loss: 1 ,  4.0021185874938965\n",
      "Epoch, Loss: 1 ,  3.985053539276123\n",
      "Epoch, Loss: 1 ,  3.9870986938476562\n",
      "Epoch, Loss: 1 ,  3.984227418899536\n",
      "Epoch, Loss: 1 ,  4.008310794830322\n",
      "Epoch, Loss: 1 ,  3.987353563308716\n",
      "Epoch, Loss: 1 ,  3.991072177886963\n",
      "Epoch, Loss: 1 ,  4.021889686584473\n",
      "Epoch, Loss: 1 ,  4.032164573669434\n",
      "Epoch, Loss: 1 ,  4.015030384063721\n",
      "Epoch, Loss: 1 ,  3.974512815475464\n",
      "Epoch, Loss: 1 ,  3.9899184703826904\n",
      "Epoch, Loss: 1 ,  3.968608856201172\n",
      "Epoch, Loss: 1 ,  4.010804176330566\n",
      "Epoch, Loss: 1 ,  4.008640766143799\n",
      "Epoch, Loss: 1 ,  3.967751979827881\n",
      "Epoch, Loss: 1 ,  4.01944637298584\n",
      "Epoch, Loss: 1 ,  3.991053342819214\n",
      "Epoch, Loss: 1 ,  4.0142974853515625\n",
      "Epoch, Loss: 1 ,  3.993929624557495\n",
      "Epoch, Loss: 1 ,  4.053794860839844\n",
      "Epoch, Loss: 1 ,  4.010655403137207\n",
      "Epoch, Loss: 1 ,  4.01302433013916\n",
      "Epoch, Loss: 1 ,  3.9577972888946533\n",
      "Epoch, Loss: 1 ,  4.035374641418457\n",
      "Epoch, Loss: 1 ,  4.0100626945495605\n",
      "Epoch, Loss: 1 ,  4.014948844909668\n",
      "Epoch, Loss: 1 ,  3.9693713188171387\n",
      "Epoch, Loss: 1 ,  3.99080228805542\n",
      "Epoch, Loss: 1 ,  4.005694389343262\n",
      "Epoch, Loss: 1 ,  4.031189441680908\n",
      "Epoch, Loss: 1 ,  4.021677017211914\n",
      "Epoch, Loss: 1 ,  4.084958076477051\n",
      "Epoch, Loss: 1 ,  3.9788308143615723\n",
      "Epoch, Loss: 1 ,  3.9606881141662598\n",
      "Epoch, Loss: 1 ,  3.9776604175567627\n",
      "Epoch, Loss: 1 ,  3.9862937927246094\n",
      "Epoch, Loss: 1 ,  4.051178932189941\n",
      "Epoch, Loss: 1 ,  3.977734088897705\n",
      "Epoch, Loss: 1 ,  4.057745456695557\n",
      "Epoch, Loss: 1 ,  4.007915496826172\n",
      "Epoch, Loss: 1 ,  4.015591621398926\n",
      "Epoch, Loss: 1 ,  3.9702916145324707\n",
      "Epoch, Loss: 1 ,  3.98687481880188\n",
      "Epoch, Loss: 1 ,  4.040664196014404\n",
      "Epoch, Loss: 1 ,  3.9701149463653564\n",
      "Epoch, Loss: 1 ,  4.075478553771973\n",
      "Epoch, Loss: 1 ,  4.019699573516846\n",
      "Epoch, Loss: 1 ,  3.9932644367218018\n",
      "Epoch, Loss: 1 ,  4.014331340789795\n",
      "Epoch, Loss: 1 ,  4.0301971435546875\n",
      "Epoch, Loss: 1 ,  3.997101306915283\n",
      "Epoch, Loss: 1 ,  4.025540351867676\n",
      "Epoch, Loss: 1 ,  4.008454322814941\n",
      "Epoch, Loss: 1 ,  3.97717547416687\n",
      "Epoch, Loss: 1 ,  4.024319648742676\n",
      "Epoch, Loss: 1 ,  4.006879806518555\n",
      "Epoch, Loss: 1 ,  3.998798370361328\n",
      "Epoch, Loss: 1 ,  4.0087385177612305\n",
      "Epoch, Loss: 1 ,  4.032312870025635\n",
      "Epoch, Loss: 1 ,  3.978184461593628\n",
      "Epoch, Loss: 1 ,  3.981600522994995\n",
      "Epoch, Loss: 1 ,  4.073851585388184\n",
      "Epoch, Loss: 1 ,  4.010605812072754\n",
      "Epoch, Loss: 1 ,  4.034373760223389\n",
      "Epoch, Loss: 1 ,  4.005741119384766\n",
      "Epoch, Loss: 1 ,  4.004605293273926\n",
      "Epoch, Loss: 1 ,  3.9918956756591797\n",
      "Epoch, Loss: 1 ,  4.016974449157715\n",
      "Epoch, Loss: 1 ,  4.034800052642822\n",
      "Epoch, Loss: 1 ,  4.022388458251953\n",
      "Epoch, Loss: 1 ,  4.008002281188965\n",
      "Epoch, Loss: 1 ,  3.9886136054992676\n",
      "Epoch, Loss: 1 ,  3.9496052265167236\n",
      "Epoch, Loss: 1 ,  4.043068885803223\n",
      "Epoch, Loss: 1 ,  3.987809658050537\n",
      "Epoch, Loss: 1 ,  4.0003252029418945\n",
      "Epoch, Loss: 1 ,  3.9800305366516113\n",
      "Epoch, Loss: 1 ,  4.004548072814941\n",
      "Epoch, Loss: 1 ,  4.039143085479736\n",
      "Epoch, Loss: 1 ,  3.9901134967803955\n",
      "Epoch, Loss: 1 ,  4.006464958190918\n",
      "Epoch, Loss: 1 ,  4.05345344543457\n",
      "Epoch, Loss: 1 ,  3.999541759490967\n",
      "Epoch, Loss: 1 ,  4.039247512817383\n",
      "Epoch, Loss: 1 ,  3.995875835418701\n",
      "Epoch, Loss: 1 ,  3.9712207317352295\n",
      "Epoch, Loss: 1 ,  3.9814670085906982\n",
      "Epoch, Loss: 1 ,  4.032410621643066\n",
      "Epoch, Loss: 1 ,  4.014107704162598\n",
      "Epoch, Loss: 1 ,  3.998288631439209\n",
      "Epoch, Loss: 1 ,  3.9945731163024902\n",
      "Epoch, Loss: 1 ,  4.0366034507751465\n",
      "Epoch, Loss: 1 ,  4.042529106140137\n",
      "Epoch, Loss: 1 ,  4.007206916809082\n",
      "Epoch, Loss: 1 ,  3.9806485176086426\n",
      "Epoch, Loss: 1 ,  3.9889678955078125\n",
      "Epoch, Loss: 1 ,  3.9959053993225098\n",
      "Epoch, Loss: 1 ,  3.9975268840789795\n",
      "Epoch, Loss: 1 ,  4.016218662261963\n",
      "Epoch, Loss: 1 ,  3.999390125274658\n",
      "Epoch, Loss: 1 ,  3.998312473297119\n",
      "Epoch, Loss: 1 ,  4.0328755378723145\n",
      "Epoch, Loss: 1 ,  3.9747142791748047\n",
      "Epoch, Loss: 1 ,  4.015547752380371\n",
      "Epoch, Loss: 1 ,  4.078625679016113\n",
      "Epoch, Loss: 1 ,  3.983030319213867\n",
      "Epoch, Loss: 1 ,  3.9792938232421875\n",
      "Epoch, Loss: 1 ,  4.042748928070068\n",
      "Epoch, Loss: 1 ,  3.984046220779419\n",
      "Epoch, Loss: 1 ,  4.019486427307129\n",
      "Epoch, Loss: 1 ,  3.9896697998046875\n",
      "Epoch, Loss: 1 ,  3.994112730026245\n",
      "Epoch, Loss: 1 ,  4.000191688537598\n",
      "Epoch, Loss: 1 ,  4.069056987762451\n",
      "Epoch, Loss: 1 ,  4.041042804718018\n",
      "Epoch, Loss: 1 ,  4.01642370223999\n",
      "Epoch, Loss: 1 ,  3.99761962890625\n",
      "Epoch, Loss: 1 ,  4.001931190490723\n",
      "Epoch, Loss: 1 ,  4.0260396003723145\n",
      "Epoch, Loss: 1 ,  3.991081953048706\n",
      "Epoch, Loss: 1 ,  3.9778850078582764\n",
      "Epoch, Loss: 1 ,  4.0072712898254395\n",
      "Epoch, Loss: 1 ,  3.984126567840576\n",
      "Epoch, Loss: 1 ,  3.9840188026428223\n",
      "Epoch, Loss: 1 ,  3.9846129417419434\n",
      "Epoch, Loss: 1 ,  4.0594635009765625\n",
      "Epoch, Loss: 1 ,  4.097228050231934\n",
      "Epoch, Loss: 1 ,  4.00383996963501\n",
      "Epoch, Loss: 1 ,  3.9921066761016846\n",
      "Epoch, Loss: 1 ,  3.9807019233703613\n",
      "Epoch, Loss: 1 ,  4.141769886016846\n",
      "Epoch, Loss: 1 ,  4.063482761383057\n",
      "Epoch, Loss: 1 ,  4.026162147521973\n",
      "Epoch, Loss: 1 ,  3.9657084941864014\n",
      "Epoch, Loss: 1 ,  3.992619037628174\n",
      "Epoch, Loss: 1 ,  4.0258965492248535\n",
      "Epoch, Loss: 1 ,  3.993391513824463\n",
      "Epoch, Loss: 1 ,  3.9952855110168457\n",
      "Epoch, Loss: 1 ,  3.9838814735412598\n",
      "Epoch, Loss: 1 ,  4.022690773010254\n",
      "Epoch, Loss: 1 ,  3.9802603721618652\n",
      "Epoch, Loss: 1 ,  3.9853999614715576\n",
      "Epoch, Loss: 1 ,  3.9673848152160645\n",
      "Epoch, Loss: 1 ,  4.00848913192749\n",
      "Epoch, Loss: 1 ,  4.025243759155273\n",
      "Epoch, Loss: 1 ,  3.9892947673797607\n",
      "Epoch, Loss: 1 ,  4.036931037902832\n",
      "Epoch, Loss: 1 ,  4.038805961608887\n",
      "Epoch, Loss: 1 ,  3.9881718158721924\n",
      "Epoch, Loss: 1 ,  3.998948335647583\n",
      "Epoch, Loss: 1 ,  3.952362060546875\n",
      "Epoch, Loss: 1 ,  3.9869656562805176\n",
      "Epoch, Loss: 1 ,  4.075985431671143\n",
      "Epoch, Loss: 1 ,  4.044459819793701\n",
      "Epoch, Loss: 1 ,  3.999736785888672\n",
      "Epoch, Loss: 1 ,  4.02460241317749\n",
      "Epoch, Loss: 1 ,  3.9989311695098877\n",
      "Epoch, Loss: 1 ,  3.979829788208008\n",
      "Epoch, Loss: 1 ,  4.025476455688477\n",
      "Epoch, Loss: 1 ,  3.9908785820007324\n",
      "Epoch, Loss: 1 ,  3.956965684890747\n",
      "Epoch, Loss: 1 ,  4.0066914558410645\n",
      "Epoch, Loss: 1 ,  4.0173139572143555\n",
      "Epoch, Loss: 1 ,  3.9999136924743652\n",
      "Epoch, Loss: 1 ,  4.015373229980469\n",
      "Epoch, Loss: 1 ,  3.9689412117004395\n",
      "Epoch, Loss: 1 ,  4.0358686447143555\n",
      "Epoch, Loss: 1 ,  4.0625152587890625\n",
      "Epoch, Loss: 1 ,  3.9932098388671875\n",
      "Epoch, Loss: 1 ,  4.016470909118652\n",
      "Epoch, Loss: 1 ,  4.017331123352051\n",
      "Epoch, Loss: 1 ,  4.0154008865356445\n",
      "Epoch, Loss: 1 ,  3.9932823181152344\n",
      "Epoch, Loss: 1 ,  3.9876933097839355\n",
      "Epoch, Loss: 1 ,  3.995000123977661\n",
      "Epoch, Loss: 1 ,  4.024219512939453\n",
      "Epoch, Loss: 1 ,  4.043466567993164\n",
      "Epoch, Loss: 1 ,  3.998811721801758\n",
      "Epoch, Loss: 1 ,  4.084455490112305\n",
      "Epoch, Loss: 1 ,  3.9970717430114746\n",
      "Epoch, Loss: 1 ,  4.003543853759766\n",
      "Epoch, Loss: 1 ,  4.0156073570251465\n",
      "Epoch, Loss: 1 ,  3.9876747131347656\n",
      "Epoch, Loss: 1 ,  4.017573356628418\n",
      "Epoch, Loss: 1 ,  4.097754955291748\n",
      "Epoch, Loss: 1 ,  4.02004861831665\n",
      "Epoch, Loss: 1 ,  4.017646789550781\n",
      "Epoch, Loss: 1 ,  4.1143364906311035\n",
      "Epoch, Loss: 1 ,  4.049196243286133\n",
      "Epoch, Loss: 1 ,  4.00177001953125\n",
      "Epoch, Loss: 1 ,  3.993811845779419\n",
      "Epoch, Loss: 1 ,  3.995278835296631\n",
      "Epoch, Loss: 1 ,  4.005670070648193\n",
      "Epoch, Loss: 1 ,  3.997170925140381\n",
      "Epoch, Loss: 1 ,  3.978928804397583\n",
      "Epoch, Loss: 1 ,  4.039371013641357\n",
      "Epoch, Loss: 1 ,  4.012176036834717\n",
      "Epoch, Loss: 1 ,  3.996196746826172\n",
      "Epoch, Loss: 1 ,  4.03887939453125\n",
      "Epoch, Loss: 1 ,  4.085790634155273\n",
      "Epoch, Loss: 1 ,  4.007163047790527\n",
      "Epoch, Loss: 1 ,  3.9472336769104004\n",
      "Epoch, Loss: 1 ,  3.980855941772461\n",
      "Epoch, Loss: 1 ,  3.9922802448272705\n",
      "Epoch, Loss: 1 ,  4.051825046539307\n",
      "Epoch, Loss: 1 ,  4.027155876159668\n",
      "Epoch, Loss: 1 ,  3.9813694953918457\n",
      "Epoch, Loss: 1 ,  4.017144680023193\n",
      "Epoch, Loss: 1 ,  4.007364749908447\n",
      "Epoch, Loss: 1 ,  3.9975180625915527\n",
      "Epoch, Loss: 1 ,  3.981811046600342\n",
      "Epoch, Loss: 1 ,  3.9487571716308594\n",
      "Epoch, Loss: 1 ,  4.021821022033691\n",
      "Epoch, Loss: 1 ,  4.046818733215332\n",
      "Epoch, Loss: 1 ,  4.017238140106201\n",
      "Epoch, Loss: 1 ,  3.979138135910034\n",
      "Epoch, Loss: 1 ,  3.991887331008911\n",
      "Epoch, Loss: 1 ,  4.002213478088379\n",
      "Epoch, Loss: 1 ,  4.005280494689941\n",
      "Epoch, Loss: 1 ,  4.0071611404418945\n",
      "Epoch, Loss: 1 ,  4.007673263549805\n",
      "Epoch, Loss: 1 ,  4.05646276473999\n",
      "epoch: 1\n",
      "Training: batch_loss: 4.009, Accuracy: 1.532\n",
      "Epoch, Loss: 2 ,  4.013981819152832\n",
      "Epoch, Loss: 2 ,  3.963416337966919\n",
      "Epoch, Loss: 2 ,  4.036589622497559\n",
      "Epoch, Loss: 2 ,  3.994717836380005\n",
      "Epoch, Loss: 2 ,  3.9997916221618652\n",
      "Epoch, Loss: 2 ,  4.044048309326172\n",
      "Epoch, Loss: 2 ,  3.9508392810821533\n",
      "Epoch, Loss: 2 ,  3.9968771934509277\n",
      "Epoch, Loss: 2 ,  3.999049663543701\n",
      "Epoch, Loss: 2 ,  4.00114631652832\n",
      "Epoch, Loss: 2 ,  4.06240701675415\n",
      "Epoch, Loss: 2 ,  3.975555896759033\n",
      "Epoch, Loss: 2 ,  4.021417140960693\n",
      "Epoch, Loss: 2 ,  3.969261884689331\n",
      "Epoch, Loss: 2 ,  4.01816987991333\n",
      "Epoch, Loss: 2 ,  4.013862609863281\n",
      "Epoch, Loss: 2 ,  3.9678521156311035\n",
      "Epoch, Loss: 2 ,  4.010565757751465\n",
      "Epoch, Loss: 2 ,  4.026533126831055\n",
      "Epoch, Loss: 2 ,  4.004178047180176\n",
      "Epoch, Loss: 2 ,  4.008050441741943\n",
      "Epoch, Loss: 2 ,  3.969393491744995\n",
      "Epoch, Loss: 2 ,  4.012197971343994\n",
      "Epoch, Loss: 2 ,  3.9928531646728516\n",
      "Epoch, Loss: 2 ,  3.9741592407226562\n",
      "Epoch, Loss: 2 ,  4.061770915985107\n",
      "Epoch, Loss: 2 ,  3.9557044506073\n",
      "Epoch, Loss: 2 ,  3.9968204498291016\n",
      "Epoch, Loss: 2 ,  3.9578003883361816\n",
      "Epoch, Loss: 2 ,  4.019811153411865\n",
      "Epoch, Loss: 2 ,  4.0163679122924805\n",
      "Epoch, Loss: 2 ,  3.942418336868286\n",
      "Epoch, Loss: 2 ,  3.9733638763427734\n",
      "Epoch, Loss: 2 ,  4.0410261154174805\n",
      "Epoch, Loss: 2 ,  4.060696601867676\n",
      "Epoch, Loss: 2 ,  3.9614436626434326\n",
      "Epoch, Loss: 2 ,  3.9734740257263184\n",
      "Epoch, Loss: 2 ,  4.012747764587402\n",
      "Epoch, Loss: 2 ,  4.010709762573242\n",
      "Epoch, Loss: 2 ,  3.99483060836792\n",
      "Epoch, Loss: 2 ,  3.9834556579589844\n",
      "Epoch, Loss: 2 ,  4.011187553405762\n",
      "Epoch, Loss: 2 ,  4.027255058288574\n",
      "Epoch, Loss: 2 ,  3.9699790477752686\n",
      "Epoch, Loss: 2 ,  4.0808305740356445\n",
      "Epoch, Loss: 2 ,  4.01157808303833\n",
      "Epoch, Loss: 2 ,  3.9924492835998535\n",
      "Epoch, Loss: 2 ,  3.9755470752716064\n",
      "Epoch, Loss: 2 ,  4.005636215209961\n",
      "Epoch, Loss: 2 ,  3.98500394821167\n",
      "Epoch, Loss: 2 ,  4.029385566711426\n",
      "Epoch, Loss: 2 ,  3.9688963890075684\n",
      "Epoch, Loss: 2 ,  4.009459972381592\n",
      "Epoch, Loss: 2 ,  4.003729820251465\n",
      "Epoch, Loss: 2 ,  4.035057544708252\n",
      "Epoch, Loss: 2 ,  4.0584492683410645\n",
      "Epoch, Loss: 2 ,  4.002819538116455\n",
      "Epoch, Loss: 2 ,  3.9670329093933105\n",
      "Epoch, Loss: 2 ,  3.971437931060791\n",
      "Epoch, Loss: 2 ,  4.036401748657227\n",
      "Epoch, Loss: 2 ,  4.033905982971191\n",
      "Epoch, Loss: 2 ,  3.994326114654541\n",
      "Epoch, Loss: 2 ,  3.9458136558532715\n",
      "Epoch, Loss: 2 ,  4.025476932525635\n",
      "Epoch, Loss: 2 ,  3.987635374069214\n",
      "Epoch, Loss: 2 ,  3.978654146194458\n",
      "Epoch, Loss: 2 ,  4.059244632720947\n",
      "Epoch, Loss: 2 ,  4.010733127593994\n",
      "Epoch, Loss: 2 ,  4.014813423156738\n",
      "Epoch, Loss: 2 ,  3.9746673107147217\n",
      "Epoch, Loss: 2 ,  4.01267147064209\n",
      "Epoch, Loss: 2 ,  4.007218360900879\n",
      "Epoch, Loss: 2 ,  3.998701572418213\n",
      "Epoch, Loss: 2 ,  4.0469207763671875\n",
      "Epoch, Loss: 2 ,  4.050647258758545\n",
      "Epoch, Loss: 2 ,  3.991516590118408\n",
      "Epoch, Loss: 2 ,  3.94610333442688\n",
      "Epoch, Loss: 2 ,  4.008473873138428\n",
      "Epoch, Loss: 2 ,  3.9877219200134277\n",
      "Epoch, Loss: 2 ,  4.033411026000977\n",
      "Epoch, Loss: 2 ,  4.006653785705566\n",
      "Epoch, Loss: 2 ,  4.077023506164551\n",
      "Epoch, Loss: 2 ,  3.9699788093566895\n",
      "Epoch, Loss: 2 ,  4.006949424743652\n",
      "Epoch, Loss: 2 ,  3.995206356048584\n",
      "Epoch, Loss: 2 ,  3.984659194946289\n",
      "Epoch, Loss: 2 ,  4.027127265930176\n",
      "Epoch, Loss: 2 ,  3.971264600753784\n",
      "Epoch, Loss: 2 ,  3.983811616897583\n",
      "Epoch, Loss: 2 ,  3.9912314414978027\n",
      "Epoch, Loss: 2 ,  4.030035972595215\n",
      "Epoch, Loss: 2 ,  3.9675960540771484\n",
      "Epoch, Loss: 2 ,  4.011236667633057\n",
      "Epoch, Loss: 2 ,  3.9876606464385986\n",
      "Epoch, Loss: 2 ,  3.9807257652282715\n",
      "Epoch, Loss: 2 ,  4.0147833824157715\n",
      "Epoch, Loss: 2 ,  4.031928062438965\n",
      "Epoch, Loss: 2 ,  4.034054279327393\n",
      "Epoch, Loss: 2 ,  3.9602246284484863\n",
      "Epoch, Loss: 2 ,  3.9782309532165527\n",
      "Epoch, Loss: 2 ,  3.989579439163208\n",
      "Epoch, Loss: 2 ,  4.071477890014648\n",
      "Epoch, Loss: 2 ,  3.9765331745147705\n",
      "Epoch, Loss: 2 ,  3.9660537242889404\n",
      "Epoch, Loss: 2 ,  3.9861888885498047\n",
      "Epoch, Loss: 2 ,  3.9658565521240234\n",
      "Epoch, Loss: 2 ,  4.004283905029297\n",
      "Epoch, Loss: 2 ,  4.024993896484375\n",
      "Epoch, Loss: 2 ,  4.003170490264893\n",
      "Epoch, Loss: 2 ,  4.022476673126221\n",
      "Epoch, Loss: 2 ,  3.9832675457000732\n",
      "Epoch, Loss: 2 ,  3.9930825233459473\n",
      "Epoch, Loss: 2 ,  3.982827663421631\n",
      "Epoch, Loss: 2 ,  4.1336259841918945\n",
      "Epoch, Loss: 2 ,  4.051202297210693\n",
      "Epoch, Loss: 2 ,  4.067514896392822\n",
      "Epoch, Loss: 2 ,  4.010184288024902\n",
      "Epoch, Loss: 2 ,  3.9763195514678955\n",
      "Epoch, Loss: 2 ,  3.9650702476501465\n",
      "Epoch, Loss: 2 ,  4.0091094970703125\n",
      "Epoch, Loss: 2 ,  4.057275295257568\n",
      "Epoch, Loss: 2 ,  3.989523410797119\n",
      "Epoch, Loss: 2 ,  4.075587272644043\n",
      "Epoch, Loss: 2 ,  4.006272315979004\n",
      "Epoch, Loss: 2 ,  4.022900581359863\n",
      "Epoch, Loss: 2 ,  4.07297420501709\n",
      "Epoch, Loss: 2 ,  3.9787323474884033\n",
      "Epoch, Loss: 2 ,  3.993155002593994\n",
      "Epoch, Loss: 2 ,  4.008255958557129\n",
      "Epoch, Loss: 2 ,  4.007242679595947\n",
      "Epoch, Loss: 2 ,  4.0159382820129395\n",
      "Epoch, Loss: 2 ,  4.067792892456055\n",
      "Epoch, Loss: 2 ,  4.016206741333008\n",
      "Epoch, Loss: 2 ,  3.9806206226348877\n",
      "Epoch, Loss: 2 ,  3.997023344039917\n",
      "Epoch, Loss: 2 ,  3.969500780105591\n",
      "Epoch, Loss: 2 ,  4.015684604644775\n",
      "Epoch, Loss: 2 ,  3.989722490310669\n",
      "Epoch, Loss: 2 ,  3.9868597984313965\n",
      "Epoch, Loss: 2 ,  4.040136337280273\n",
      "Epoch, Loss: 2 ,  4.088789939880371\n",
      "Epoch, Loss: 2 ,  3.979091167449951\n",
      "Epoch, Loss: 2 ,  4.031804084777832\n",
      "Epoch, Loss: 2 ,  4.047341346740723\n",
      "Epoch, Loss: 2 ,  4.035408973693848\n",
      "Epoch, Loss: 2 ,  4.0402960777282715\n",
      "Epoch, Loss: 2 ,  4.000203609466553\n",
      "Epoch, Loss: 2 ,  4.015341281890869\n",
      "Epoch, Loss: 2 ,  4.030682563781738\n",
      "Epoch, Loss: 2 ,  4.026106834411621\n",
      "Epoch, Loss: 2 ,  3.977703094482422\n",
      "Epoch, Loss: 2 ,  3.994919538497925\n",
      "Epoch, Loss: 2 ,  3.985591173171997\n",
      "Epoch, Loss: 2 ,  3.982682704925537\n",
      "Epoch, Loss: 2 ,  4.0516486167907715\n",
      "Epoch, Loss: 2 ,  4.00020170211792\n",
      "Epoch, Loss: 2 ,  4.054980278015137\n",
      "Epoch, Loss: 2 ,  4.081316947937012\n",
      "Epoch, Loss: 2 ,  3.984999179840088\n",
      "Epoch, Loss: 2 ,  4.060296535491943\n",
      "Epoch, Loss: 2 ,  4.014834403991699\n",
      "Epoch, Loss: 2 ,  3.997390031814575\n",
      "Epoch, Loss: 2 ,  4.005429744720459\n",
      "Epoch, Loss: 2 ,  4.000538349151611\n",
      "Epoch, Loss: 2 ,  3.9978199005126953\n",
      "Epoch, Loss: 2 ,  4.000829696655273\n",
      "Epoch, Loss: 2 ,  4.004569053649902\n",
      "Epoch, Loss: 2 ,  3.982201337814331\n",
      "Epoch, Loss: 2 ,  4.068996906280518\n",
      "Epoch, Loss: 2 ,  4.016117572784424\n",
      "Epoch, Loss: 2 ,  4.022660255432129\n",
      "Epoch, Loss: 2 ,  4.002686977386475\n",
      "Epoch, Loss: 2 ,  4.019927978515625\n",
      "Epoch, Loss: 2 ,  4.0006327629089355\n",
      "Epoch, Loss: 2 ,  4.036183834075928\n",
      "Epoch, Loss: 2 ,  3.9574851989746094\n",
      "Epoch, Loss: 2 ,  4.000456809997559\n",
      "Epoch, Loss: 2 ,  3.99634051322937\n",
      "Epoch, Loss: 2 ,  4.0121588706970215\n",
      "Epoch, Loss: 2 ,  4.007576942443848\n",
      "Epoch, Loss: 2 ,  3.956785202026367\n",
      "Epoch, Loss: 2 ,  3.9729371070861816\n",
      "Epoch, Loss: 2 ,  3.993853807449341\n",
      "Epoch, Loss: 2 ,  4.107180595397949\n",
      "Epoch, Loss: 2 ,  4.014752388000488\n",
      "Epoch, Loss: 2 ,  4.00576114654541\n",
      "Epoch, Loss: 2 ,  4.002230644226074\n",
      "Epoch, Loss: 2 ,  4.02871036529541\n",
      "Epoch, Loss: 2 ,  3.9874329566955566\n",
      "Epoch, Loss: 2 ,  4.002561092376709\n",
      "Epoch, Loss: 2 ,  4.0566487312316895\n",
      "Epoch, Loss: 2 ,  4.043460845947266\n",
      "Epoch, Loss: 2 ,  3.9998831748962402\n",
      "Epoch, Loss: 2 ,  4.023950576782227\n",
      "Epoch, Loss: 2 ,  4.019965171813965\n",
      "Epoch, Loss: 2 ,  4.000241279602051\n",
      "Epoch, Loss: 2 ,  3.9716529846191406\n",
      "Epoch, Loss: 2 ,  4.055994033813477\n",
      "Epoch, Loss: 2 ,  3.9865882396698\n",
      "Epoch, Loss: 2 ,  4.0149617195129395\n",
      "Epoch, Loss: 2 ,  3.9983856678009033\n",
      "Epoch, Loss: 2 ,  3.9626266956329346\n",
      "Epoch, Loss: 2 ,  4.018317699432373\n",
      "Epoch, Loss: 2 ,  4.046496868133545\n",
      "Epoch, Loss: 2 ,  4.193110466003418\n",
      "Epoch, Loss: 2 ,  4.028369426727295\n",
      "Epoch, Loss: 2 ,  4.037301540374756\n",
      "Epoch, Loss: 2 ,  3.9788002967834473\n",
      "Epoch, Loss: 2 ,  4.087396621704102\n",
      "Epoch, Loss: 2 ,  3.98199200630188\n",
      "Epoch, Loss: 2 ,  3.9753432273864746\n",
      "Epoch, Loss: 2 ,  4.0404863357543945\n",
      "Epoch, Loss: 2 ,  3.993185520172119\n",
      "Epoch, Loss: 2 ,  4.0357513427734375\n",
      "Epoch, Loss: 2 ,  4.093737602233887\n",
      "Epoch, Loss: 2 ,  3.9757087230682373\n",
      "Epoch, Loss: 2 ,  4.01016902923584\n",
      "Epoch, Loss: 2 ,  4.000569820404053\n",
      "Epoch, Loss: 2 ,  3.9902853965759277\n",
      "Epoch, Loss: 2 ,  4.134960651397705\n",
      "Epoch, Loss: 2 ,  3.9642391204833984\n",
      "Epoch, Loss: 2 ,  4.057629108428955\n",
      "Epoch, Loss: 2 ,  3.9980010986328125\n",
      "Epoch, Loss: 2 ,  4.010693073272705\n",
      "Epoch, Loss: 2 ,  3.992955446243286\n",
      "Epoch, Loss: 2 ,  3.9763901233673096\n",
      "Epoch, Loss: 2 ,  3.979198932647705\n",
      "Epoch, Loss: 2 ,  4.0259623527526855\n",
      "Epoch, Loss: 2 ,  3.9937045574188232\n",
      "epoch: 2\n",
      "Training: batch_loss: 4.009, Accuracy: 1.503\n",
      "Epoch, Loss: 3 ,  3.98675274848938\n",
      "Epoch, Loss: 3 ,  3.988997220993042\n",
      "Epoch, Loss: 3 ,  3.97747540473938\n",
      "Epoch, Loss: 3 ,  3.980874538421631\n",
      "Epoch, Loss: 3 ,  3.9940853118896484\n",
      "Epoch, Loss: 3 ,  4.0149407386779785\n",
      "Epoch, Loss: 3 ,  4.157291412353516\n",
      "Epoch, Loss: 3 ,  3.990476608276367\n",
      "Epoch, Loss: 3 ,  3.9981231689453125\n",
      "Epoch, Loss: 3 ,  3.988610029220581\n",
      "Epoch, Loss: 3 ,  3.9818081855773926\n",
      "Epoch, Loss: 3 ,  4.018320560455322\n",
      "Epoch, Loss: 3 ,  3.9839420318603516\n",
      "Epoch, Loss: 3 ,  3.999300479888916\n",
      "Epoch, Loss: 3 ,  3.9941909313201904\n",
      "Epoch, Loss: 3 ,  3.9652066230773926\n",
      "Epoch, Loss: 3 ,  3.9844956398010254\n",
      "Epoch, Loss: 3 ,  3.978847026824951\n",
      "Epoch, Loss: 3 ,  3.9164555072784424\n",
      "Epoch, Loss: 3 ,  3.9593231678009033\n",
      "Epoch, Loss: 3 ,  4.011375427246094\n",
      "Epoch, Loss: 3 ,  3.947415828704834\n",
      "Epoch, Loss: 3 ,  4.013436317443848\n",
      "Epoch, Loss: 3 ,  3.9658493995666504\n",
      "Epoch, Loss: 3 ,  4.11544132232666\n",
      "Epoch, Loss: 3 ,  3.970885753631592\n",
      "Epoch, Loss: 3 ,  4.000901699066162\n",
      "Epoch, Loss: 3 ,  3.9887993335723877\n",
      "Epoch, Loss: 3 ,  3.9766082763671875\n",
      "Epoch, Loss: 3 ,  3.98992919921875\n",
      "Epoch, Loss: 3 ,  4.007575035095215\n",
      "Epoch, Loss: 3 ,  3.9662933349609375\n",
      "Epoch, Loss: 3 ,  4.003627300262451\n",
      "Epoch, Loss: 3 ,  3.9864630699157715\n",
      "Epoch, Loss: 3 ,  3.9831008911132812\n",
      "Epoch, Loss: 3 ,  4.006577491760254\n",
      "Epoch, Loss: 3 ,  4.029801368713379\n",
      "Epoch, Loss: 3 ,  4.046875953674316\n",
      "Epoch, Loss: 3 ,  4.023590087890625\n",
      "Epoch, Loss: 3 ,  4.000845432281494\n",
      "Epoch, Loss: 3 ,  4.027167797088623\n",
      "Epoch, Loss: 3 ,  3.9532649517059326\n",
      "Epoch, Loss: 3 ,  3.9767863750457764\n",
      "Epoch, Loss: 3 ,  4.036036491394043\n",
      "Epoch, Loss: 3 ,  3.9728684425354004\n",
      "Epoch, Loss: 3 ,  3.989917039871216\n",
      "Epoch, Loss: 3 ,  3.9996681213378906\n",
      "Epoch, Loss: 3 ,  3.973578929901123\n",
      "Epoch, Loss: 3 ,  4.089213848114014\n",
      "Epoch, Loss: 3 ,  4.011173248291016\n",
      "Epoch, Loss: 3 ,  4.016135215759277\n",
      "Epoch, Loss: 3 ,  4.009666442871094\n",
      "Epoch, Loss: 3 ,  3.998140811920166\n",
      "Epoch, Loss: 3 ,  3.9790992736816406\n",
      "Epoch, Loss: 3 ,  4.00902795791626\n",
      "Epoch, Loss: 3 ,  4.0270795822143555\n",
      "Epoch, Loss: 3 ,  4.116418361663818\n",
      "Epoch, Loss: 3 ,  4.0067644119262695\n",
      "Epoch, Loss: 3 ,  4.058715343475342\n",
      "Epoch, Loss: 3 ,  3.9953982830047607\n",
      "Epoch, Loss: 3 ,  3.9799046516418457\n",
      "Epoch, Loss: 3 ,  3.9694747924804688\n",
      "Epoch, Loss: 3 ,  4.018060684204102\n",
      "Epoch, Loss: 3 ,  4.030226230621338\n",
      "Epoch, Loss: 3 ,  3.997697114944458\n",
      "Epoch, Loss: 3 ,  3.950119733810425\n",
      "Epoch, Loss: 3 ,  3.971633195877075\n",
      "Epoch, Loss: 3 ,  3.9844727516174316\n",
      "Epoch, Loss: 3 ,  4.005425453186035\n",
      "Epoch, Loss: 3 ,  3.994751453399658\n",
      "Epoch, Loss: 3 ,  4.040743827819824\n",
      "Epoch, Loss: 3 ,  4.0154829025268555\n",
      "Epoch, Loss: 3 ,  3.9400291442871094\n",
      "Epoch, Loss: 3 ,  3.9951560497283936\n",
      "Epoch, Loss: 3 ,  4.005174160003662\n",
      "Epoch, Loss: 3 ,  4.0191731452941895\n",
      "Epoch, Loss: 3 ,  3.9581546783447266\n",
      "Epoch, Loss: 3 ,  3.9435927867889404\n",
      "Epoch, Loss: 3 ,  3.9697487354278564\n",
      "Epoch, Loss: 3 ,  3.9771857261657715\n",
      "Epoch, Loss: 3 ,  3.9829659461975098\n",
      "Epoch, Loss: 3 ,  3.999556064605713\n",
      "Epoch, Loss: 3 ,  4.041672706604004\n",
      "Epoch, Loss: 3 ,  3.9814724922180176\n",
      "Epoch, Loss: 3 ,  3.9904866218566895\n",
      "Epoch, Loss: 3 ,  3.9555442333221436\n",
      "Epoch, Loss: 3 ,  3.9253463745117188\n",
      "Epoch, Loss: 3 ,  3.997906446456909\n",
      "Epoch, Loss: 3 ,  4.000958442687988\n",
      "Epoch, Loss: 3 ,  3.974398374557495\n",
      "Epoch, Loss: 3 ,  4.080145359039307\n",
      "Epoch, Loss: 3 ,  4.001964092254639\n",
      "Epoch, Loss: 3 ,  3.9786925315856934\n",
      "Epoch, Loss: 3 ,  3.993182420730591\n",
      "Epoch, Loss: 3 ,  4.038006782531738\n",
      "Epoch, Loss: 3 ,  4.030203342437744\n",
      "Epoch, Loss: 3 ,  4.070481777191162\n",
      "Epoch, Loss: 3 ,  3.9787933826446533\n",
      "Epoch, Loss: 3 ,  4.015912055969238\n",
      "Epoch, Loss: 3 ,  4.014395236968994\n",
      "Epoch, Loss: 3 ,  4.029324054718018\n",
      "Epoch, Loss: 3 ,  3.959505796432495\n",
      "Epoch, Loss: 3 ,  4.028088569641113\n",
      "Epoch, Loss: 3 ,  4.019774436950684\n",
      "Epoch, Loss: 3 ,  4.033270359039307\n",
      "Epoch, Loss: 3 ,  4.0060601234436035\n",
      "Epoch, Loss: 3 ,  3.988706111907959\n",
      "Epoch, Loss: 3 ,  4.022402763366699\n",
      "Epoch, Loss: 3 ,  4.075489521026611\n",
      "Epoch, Loss: 3 ,  3.9796385765075684\n",
      "Epoch, Loss: 3 ,  3.981698989868164\n",
      "Epoch, Loss: 3 ,  4.033848762512207\n",
      "Epoch, Loss: 3 ,  4.021297931671143\n",
      "Epoch, Loss: 3 ,  4.045741081237793\n",
      "Epoch, Loss: 3 ,  3.9850845336914062\n",
      "Epoch, Loss: 3 ,  3.9995923042297363\n",
      "Epoch, Loss: 3 ,  4.040277004241943\n",
      "Epoch, Loss: 3 ,  4.123776435852051\n",
      "Epoch, Loss: 3 ,  4.1398420333862305\n",
      "Epoch, Loss: 3 ,  4.036444664001465\n",
      "Epoch, Loss: 3 ,  4.003366947174072\n",
      "Epoch, Loss: 3 ,  3.993781328201294\n",
      "Epoch, Loss: 3 ,  3.9584498405456543\n",
      "Epoch, Loss: 3 ,  4.094083309173584\n",
      "Epoch, Loss: 3 ,  3.9929709434509277\n",
      "Epoch, Loss: 3 ,  4.027584552764893\n",
      "Epoch, Loss: 3 ,  4.0201005935668945\n",
      "Epoch, Loss: 3 ,  4.004601001739502\n",
      "Epoch, Loss: 3 ,  3.9747447967529297\n",
      "Epoch, Loss: 3 ,  4.035123825073242\n",
      "Epoch, Loss: 3 ,  4.020566940307617\n",
      "Epoch, Loss: 3 ,  3.976097822189331\n",
      "Epoch, Loss: 3 ,  3.981783390045166\n",
      "Epoch, Loss: 3 ,  3.9955172538757324\n",
      "Epoch, Loss: 3 ,  4.053018569946289\n",
      "Epoch, Loss: 3 ,  3.9809765815734863\n",
      "Epoch, Loss: 3 ,  4.072353363037109\n",
      "Epoch, Loss: 3 ,  4.065885066986084\n",
      "Epoch, Loss: 3 ,  4.073048114776611\n",
      "Epoch, Loss: 3 ,  4.001404762268066\n",
      "Epoch, Loss: 3 ,  3.9774105548858643\n",
      "Epoch, Loss: 3 ,  4.0240888595581055\n",
      "Epoch, Loss: 3 ,  3.950047731399536\n",
      "Epoch, Loss: 3 ,  3.986584186553955\n",
      "Epoch, Loss: 3 ,  4.0011515617370605\n",
      "Epoch, Loss: 3 ,  4.006400108337402\n",
      "Epoch, Loss: 3 ,  3.9608511924743652\n",
      "Epoch, Loss: 3 ,  3.989614486694336\n",
      "Epoch, Loss: 3 ,  4.096139430999756\n",
      "Epoch, Loss: 3 ,  3.9985835552215576\n",
      "Epoch, Loss: 3 ,  3.9874675273895264\n",
      "Epoch, Loss: 3 ,  3.9580330848693848\n",
      "Epoch, Loss: 3 ,  4.018288612365723\n",
      "Epoch, Loss: 3 ,  4.143931865692139\n",
      "Epoch, Loss: 3 ,  4.031317710876465\n",
      "Epoch, Loss: 3 ,  4.000356674194336\n",
      "Epoch, Loss: 3 ,  3.9922618865966797\n",
      "Epoch, Loss: 3 ,  4.01959228515625\n",
      "Epoch, Loss: 3 ,  4.024514675140381\n",
      "Epoch, Loss: 3 ,  4.1514129638671875\n",
      "Epoch, Loss: 3 ,  3.9833731651306152\n",
      "Epoch, Loss: 3 ,  4.0290069580078125\n",
      "Epoch, Loss: 3 ,  4.0462327003479\n",
      "Epoch, Loss: 3 ,  3.9963326454162598\n",
      "Epoch, Loss: 3 ,  4.06745719909668\n",
      "Epoch, Loss: 3 ,  3.998265027999878\n",
      "Epoch, Loss: 3 ,  3.989621639251709\n",
      "Epoch, Loss: 3 ,  4.043415546417236\n",
      "Epoch, Loss: 3 ,  3.9939990043640137\n",
      "Epoch, Loss: 3 ,  3.9784648418426514\n",
      "Epoch, Loss: 3 ,  3.9920573234558105\n",
      "Epoch, Loss: 3 ,  4.06846284866333\n",
      "Epoch, Loss: 3 ,  3.997697114944458\n",
      "Epoch, Loss: 3 ,  4.0014214515686035\n",
      "Epoch, Loss: 3 ,  4.005728244781494\n",
      "Epoch, Loss: 3 ,  3.988340377807617\n",
      "Epoch, Loss: 3 ,  3.992885112762451\n",
      "Epoch, Loss: 3 ,  4.036507606506348\n",
      "Epoch, Loss: 3 ,  4.000966548919678\n",
      "Epoch, Loss: 3 ,  4.020617961883545\n",
      "Epoch, Loss: 3 ,  3.9579131603240967\n",
      "Epoch, Loss: 3 ,  4.030887603759766\n",
      "Epoch, Loss: 3 ,  4.012031078338623\n",
      "Epoch, Loss: 3 ,  4.04949426651001\n",
      "Epoch, Loss: 3 ,  4.014902591705322\n",
      "Epoch, Loss: 3 ,  4.035611152648926\n",
      "Epoch, Loss: 3 ,  3.9999618530273438\n",
      "Epoch, Loss: 3 ,  4.083928108215332\n",
      "Epoch, Loss: 3 ,  4.008635997772217\n",
      "Epoch, Loss: 3 ,  3.9922027587890625\n",
      "Epoch, Loss: 3 ,  3.9723427295684814\n",
      "Epoch, Loss: 3 ,  3.982144832611084\n",
      "Epoch, Loss: 3 ,  3.9857304096221924\n",
      "Epoch, Loss: 3 ,  3.9715895652770996\n",
      "Epoch, Loss: 3 ,  3.992795944213867\n",
      "Epoch, Loss: 3 ,  4.064414024353027\n",
      "Epoch, Loss: 3 ,  4.006009101867676\n",
      "Epoch, Loss: 3 ,  4.005894660949707\n",
      "Epoch, Loss: 3 ,  4.107385635375977\n",
      "Epoch, Loss: 3 ,  4.006641864776611\n",
      "Epoch, Loss: 3 ,  4.037787437438965\n",
      "Epoch, Loss: 3 ,  3.922734022140503\n",
      "Epoch, Loss: 3 ,  4.036975860595703\n",
      "Epoch, Loss: 3 ,  4.0656843185424805\n",
      "Epoch, Loss: 3 ,  4.04171085357666\n",
      "Epoch, Loss: 3 ,  3.9935219287872314\n",
      "Epoch, Loss: 3 ,  4.004677772521973\n",
      "Epoch, Loss: 3 ,  4.017571926116943\n",
      "Epoch, Loss: 3 ,  4.053011417388916\n",
      "Epoch, Loss: 3 ,  3.992385149002075\n",
      "Epoch, Loss: 3 ,  4.007586479187012\n",
      "Epoch, Loss: 3 ,  3.9776077270507812\n",
      "Epoch, Loss: 3 ,  3.9979400634765625\n",
      "Epoch, Loss: 3 ,  4.071125030517578\n",
      "Epoch, Loss: 3 ,  4.0174946784973145\n",
      "Epoch, Loss: 3 ,  3.995048999786377\n",
      "Epoch, Loss: 3 ,  4.000865936279297\n",
      "Epoch, Loss: 3 ,  3.9894626140594482\n",
      "Epoch, Loss: 3 ,  3.9688754081726074\n",
      "Epoch, Loss: 3 ,  4.026058197021484\n",
      "Epoch, Loss: 3 ,  4.000237464904785\n",
      "Epoch, Loss: 3 ,  4.014146327972412\n",
      "Epoch, Loss: 3 ,  4.15775203704834\n",
      "Epoch, Loss: 3 ,  4.028090476989746\n",
      "Epoch, Loss: 3 ,  3.9792075157165527\n",
      "Epoch, Loss: 3 ,  4.020411968231201\n",
      "Epoch, Loss: 3 ,  4.020425796508789\n",
      "Epoch, Loss: 3 ,  4.077052116394043\n",
      "Epoch, Loss: 3 ,  4.043377876281738\n",
      "epoch: 3\n",
      "Training: batch_loss: 4.010, Accuracy: 1.500\n",
      "Epoch, Loss: 4 ,  4.052956581115723\n",
      "Epoch, Loss: 4 ,  3.985131025314331\n",
      "Epoch, Loss: 4 ,  3.982609987258911\n",
      "Epoch, Loss: 4 ,  3.979402542114258\n",
      "Epoch, Loss: 4 ,  3.9866745471954346\n",
      "Epoch, Loss: 4 ,  4.011926651000977\n",
      "Epoch, Loss: 4 ,  3.961996555328369\n",
      "Epoch, Loss: 4 ,  3.9808380603790283\n",
      "Epoch, Loss: 4 ,  4.170135498046875\n",
      "Epoch, Loss: 4 ,  3.960409641265869\n",
      "Epoch, Loss: 4 ,  3.9895973205566406\n",
      "Epoch, Loss: 4 ,  3.99045991897583\n",
      "Epoch, Loss: 4 ,  3.98063325881958\n",
      "Epoch, Loss: 4 ,  4.008574485778809\n",
      "Epoch, Loss: 4 ,  4.00298547744751\n",
      "Epoch, Loss: 4 ,  4.030057907104492\n",
      "Epoch, Loss: 4 ,  3.9892361164093018\n",
      "Epoch, Loss: 4 ,  4.01558256149292\n",
      "Epoch, Loss: 4 ,  3.9913172721862793\n",
      "Epoch, Loss: 4 ,  3.9473013877868652\n",
      "Epoch, Loss: 4 ,  3.959782361984253\n",
      "Epoch, Loss: 4 ,  4.000704288482666\n",
      "Epoch, Loss: 4 ,  3.954409122467041\n",
      "Epoch, Loss: 4 ,  4.068355560302734\n",
      "Epoch, Loss: 4 ,  4.007985591888428\n",
      "Epoch, Loss: 4 ,  4.000243186950684\n",
      "Epoch, Loss: 4 ,  4.012880325317383\n",
      "Epoch, Loss: 4 ,  3.995922803878784\n",
      "Epoch, Loss: 4 ,  4.073293209075928\n",
      "Epoch, Loss: 4 ,  4.039846420288086\n",
      "Epoch, Loss: 4 ,  3.968498945236206\n",
      "Epoch, Loss: 4 ,  4.047976970672607\n",
      "Epoch, Loss: 4 ,  4.005084037780762\n",
      "Epoch, Loss: 4 ,  4.0504279136657715\n",
      "Epoch, Loss: 4 ,  3.9795002937316895\n",
      "Epoch, Loss: 4 ,  4.004111289978027\n",
      "Epoch, Loss: 4 ,  4.120945930480957\n",
      "Epoch, Loss: 4 ,  4.016877174377441\n",
      "Epoch, Loss: 4 ,  3.9934959411621094\n",
      "Epoch, Loss: 4 ,  3.9775547981262207\n",
      "Epoch, Loss: 4 ,  4.03361701965332\n",
      "Epoch, Loss: 4 ,  4.102502346038818\n",
      "Epoch, Loss: 4 ,  3.981717348098755\n",
      "Epoch, Loss: 4 ,  3.9803855419158936\n",
      "Epoch, Loss: 4 ,  3.9855575561523438\n",
      "Epoch, Loss: 4 ,  3.9979844093322754\n",
      "Epoch, Loss: 4 ,  3.9684855937957764\n",
      "Epoch, Loss: 4 ,  3.9559245109558105\n",
      "Epoch, Loss: 4 ,  4.0303778648376465\n",
      "Epoch, Loss: 4 ,  3.946934938430786\n",
      "Epoch, Loss: 4 ,  4.058837413787842\n",
      "Epoch, Loss: 4 ,  3.9889278411865234\n",
      "Epoch, Loss: 4 ,  4.010145664215088\n",
      "Epoch, Loss: 4 ,  4.043517589569092\n",
      "Epoch, Loss: 4 ,  4.028646945953369\n",
      "Epoch, Loss: 4 ,  4.018339157104492\n",
      "Epoch, Loss: 4 ,  3.98903226852417\n",
      "Epoch, Loss: 4 ,  4.007341384887695\n",
      "Epoch, Loss: 4 ,  3.9969379901885986\n",
      "Epoch, Loss: 4 ,  3.9754955768585205\n",
      "Epoch, Loss: 4 ,  4.010801792144775\n",
      "Epoch, Loss: 4 ,  4.010944843292236\n",
      "Epoch, Loss: 4 ,  3.956334352493286\n",
      "Epoch, Loss: 4 ,  3.942892551422119\n",
      "Epoch, Loss: 4 ,  4.01021671295166\n",
      "Epoch, Loss: 4 ,  3.9890646934509277\n",
      "Epoch, Loss: 4 ,  3.9731197357177734\n",
      "Epoch, Loss: 4 ,  3.968172788619995\n",
      "Epoch, Loss: 4 ,  4.005886077880859\n",
      "Epoch, Loss: 4 ,  3.978895902633667\n",
      "Epoch, Loss: 4 ,  4.009027481079102\n",
      "Epoch, Loss: 4 ,  3.982593536376953\n",
      "Epoch, Loss: 4 ,  4.009956359863281\n",
      "Epoch, Loss: 4 ,  4.006816864013672\n",
      "Epoch, Loss: 4 ,  3.9973278045654297\n",
      "Epoch, Loss: 4 ,  4.067643165588379\n",
      "Epoch, Loss: 4 ,  4.033109664916992\n",
      "Epoch, Loss: 4 ,  4.083690166473389\n",
      "Epoch, Loss: 4 ,  3.9616661071777344\n",
      "Epoch, Loss: 4 ,  4.015291213989258\n",
      "Epoch, Loss: 4 ,  4.027218818664551\n",
      "Epoch, Loss: 4 ,  3.9972712993621826\n",
      "Epoch, Loss: 4 ,  4.013613700866699\n",
      "Epoch, Loss: 4 ,  4.003763675689697\n",
      "Epoch, Loss: 4 ,  3.9376883506774902\n",
      "Epoch, Loss: 4 ,  3.9765734672546387\n",
      "Epoch, Loss: 4 ,  4.00736141204834\n",
      "Epoch, Loss: 4 ,  3.999208927154541\n",
      "Epoch, Loss: 4 ,  3.9740653038024902\n",
      "Epoch, Loss: 4 ,  3.993056535720825\n",
      "Epoch, Loss: 4 ,  3.9760100841522217\n",
      "Epoch, Loss: 4 ,  4.038233280181885\n",
      "Epoch, Loss: 4 ,  4.035723686218262\n",
      "Epoch, Loss: 4 ,  4.050959587097168\n",
      "Epoch, Loss: 4 ,  4.0029191970825195\n",
      "Epoch, Loss: 4 ,  3.977369785308838\n",
      "Epoch, Loss: 4 ,  4.003129005432129\n",
      "Epoch, Loss: 4 ,  4.0068864822387695\n",
      "Epoch, Loss: 4 ,  3.9636757373809814\n",
      "Epoch, Loss: 4 ,  3.9877917766571045\n",
      "Epoch, Loss: 4 ,  4.035346031188965\n",
      "Epoch, Loss: 4 ,  4.010003089904785\n",
      "Epoch, Loss: 4 ,  3.9937984943389893\n",
      "Epoch, Loss: 4 ,  3.997659683227539\n",
      "Epoch, Loss: 4 ,  3.983954668045044\n",
      "Epoch, Loss: 4 ,  3.9918570518493652\n",
      "Epoch, Loss: 4 ,  4.078793525695801\n",
      "Epoch, Loss: 4 ,  3.9816813468933105\n",
      "Epoch, Loss: 4 ,  4.007511615753174\n",
      "Epoch, Loss: 4 ,  4.040914058685303\n",
      "Epoch, Loss: 4 ,  3.9910502433776855\n",
      "Epoch, Loss: 4 ,  4.023326873779297\n",
      "Epoch, Loss: 4 ,  4.042749881744385\n",
      "Epoch, Loss: 4 ,  4.036764144897461\n",
      "Epoch, Loss: 4 ,  4.0111565589904785\n",
      "Epoch, Loss: 4 ,  3.9816131591796875\n",
      "Epoch, Loss: 4 ,  4.083624839782715\n",
      "Epoch, Loss: 4 ,  4.000277996063232\n",
      "Epoch, Loss: 4 ,  3.9501290321350098\n",
      "Epoch, Loss: 4 ,  3.9798483848571777\n",
      "Epoch, Loss: 4 ,  3.9454360008239746\n",
      "Epoch, Loss: 4 ,  3.9893593788146973\n",
      "Epoch, Loss: 4 ,  3.9974002838134766\n",
      "Epoch, Loss: 4 ,  4.001663684844971\n",
      "Epoch, Loss: 4 ,  3.966841459274292\n",
      "Epoch, Loss: 4 ,  4.000128269195557\n",
      "Epoch, Loss: 4 ,  3.9892284870147705\n",
      "Epoch, Loss: 4 ,  3.99113130569458\n",
      "Epoch, Loss: 4 ,  4.082577705383301\n",
      "Epoch, Loss: 4 ,  4.035940647125244\n",
      "Epoch, Loss: 4 ,  4.0244951248168945\n",
      "Epoch, Loss: 4 ,  3.970970630645752\n",
      "Epoch, Loss: 4 ,  4.063666343688965\n",
      "Epoch, Loss: 4 ,  3.996314287185669\n",
      "Epoch, Loss: 4 ,  4.011873722076416\n",
      "Epoch, Loss: 4 ,  3.986207962036133\n",
      "Epoch, Loss: 4 ,  4.026355266571045\n",
      "Epoch, Loss: 4 ,  4.082203388214111\n",
      "Epoch, Loss: 4 ,  4.094034194946289\n",
      "Epoch, Loss: 4 ,  4.007830619812012\n",
      "Epoch, Loss: 4 ,  3.9878029823303223\n",
      "Epoch, Loss: 4 ,  3.998852491378784\n",
      "Epoch, Loss: 4 ,  4.030826091766357\n",
      "Epoch, Loss: 4 ,  3.963789701461792\n",
      "Epoch, Loss: 4 ,  4.095867156982422\n",
      "Epoch, Loss: 4 ,  4.007627964019775\n",
      "Epoch, Loss: 4 ,  3.984560489654541\n",
      "Epoch, Loss: 4 ,  4.039196968078613\n",
      "Epoch, Loss: 4 ,  4.020264625549316\n",
      "Epoch, Loss: 4 ,  4.001384735107422\n",
      "Epoch, Loss: 4 ,  4.018581867218018\n",
      "Epoch, Loss: 4 ,  4.058538436889648\n",
      "Epoch, Loss: 4 ,  4.051159858703613\n",
      "Epoch, Loss: 4 ,  4.0160627365112305\n",
      "Epoch, Loss: 4 ,  4.0183539390563965\n",
      "Epoch, Loss: 4 ,  4.026455402374268\n",
      "Epoch, Loss: 4 ,  4.098413467407227\n",
      "Epoch, Loss: 4 ,  4.096767902374268\n",
      "Epoch, Loss: 4 ,  4.018475532531738\n",
      "Epoch, Loss: 4 ,  4.0163702964782715\n",
      "Epoch, Loss: 4 ,  3.9738879203796387\n",
      "Epoch, Loss: 4 ,  3.983854293823242\n",
      "Epoch, Loss: 4 ,  3.968806505203247\n",
      "Epoch, Loss: 4 ,  3.9699718952178955\n",
      "Epoch, Loss: 4 ,  4.004765033721924\n",
      "Epoch, Loss: 4 ,  3.9745707511901855\n",
      "Epoch, Loss: 4 ,  4.02216100692749\n",
      "Epoch, Loss: 4 ,  4.041896820068359\n",
      "Epoch, Loss: 4 ,  3.986325740814209\n",
      "Epoch, Loss: 4 ,  4.103106498718262\n",
      "Epoch, Loss: 4 ,  3.9895148277282715\n",
      "Epoch, Loss: 4 ,  4.0127763748168945\n",
      "Epoch, Loss: 4 ,  4.013130187988281\n",
      "Epoch, Loss: 4 ,  4.017675399780273\n",
      "Epoch, Loss: 4 ,  3.960991621017456\n",
      "Epoch, Loss: 4 ,  4.005683898925781\n",
      "Epoch, Loss: 4 ,  3.9803624153137207\n",
      "Epoch, Loss: 4 ,  3.9526965618133545\n",
      "Epoch, Loss: 4 ,  4.066743850708008\n",
      "Epoch, Loss: 4 ,  4.009108543395996\n",
      "Epoch, Loss: 4 ,  4.008064270019531\n",
      "Epoch, Loss: 4 ,  4.004128456115723\n",
      "Epoch, Loss: 4 ,  4.005516052246094\n",
      "Epoch, Loss: 4 ,  3.9749367237091064\n",
      "Epoch, Loss: 4 ,  4.031970024108887\n",
      "Epoch, Loss: 4 ,  3.976086139678955\n",
      "Epoch, Loss: 4 ,  3.9864144325256348\n",
      "Epoch, Loss: 4 ,  3.967736005783081\n",
      "Epoch, Loss: 4 ,  3.9906132221221924\n",
      "Epoch, Loss: 4 ,  3.9641051292419434\n",
      "Epoch, Loss: 4 ,  4.0192060470581055\n",
      "Epoch, Loss: 4 ,  4.027087211608887\n",
      "Epoch, Loss: 4 ,  4.053916931152344\n",
      "Epoch, Loss: 4 ,  3.999512195587158\n",
      "Epoch, Loss: 4 ,  4.006414413452148\n",
      "Epoch, Loss: 4 ,  4.052340030670166\n",
      "Epoch, Loss: 4 ,  3.9885761737823486\n",
      "Epoch, Loss: 4 ,  4.024744510650635\n",
      "Epoch, Loss: 4 ,  4.0038652420043945\n",
      "Epoch, Loss: 4 ,  4.090654373168945\n",
      "Epoch, Loss: 4 ,  3.993375301361084\n",
      "Epoch, Loss: 4 ,  3.9939754009246826\n",
      "Epoch, Loss: 4 ,  3.9959018230438232\n",
      "Epoch, Loss: 4 ,  4.092658042907715\n",
      "Epoch, Loss: 4 ,  4.087131023406982\n",
      "Epoch, Loss: 4 ,  4.033883094787598\n",
      "Epoch, Loss: 4 ,  3.975780963897705\n",
      "Epoch, Loss: 4 ,  4.027304172515869\n",
      "Epoch, Loss: 4 ,  4.0570173263549805\n",
      "Epoch, Loss: 4 ,  4.0047454833984375\n",
      "Epoch, Loss: 4 ,  3.989983320236206\n",
      "Epoch, Loss: 4 ,  4.0521392822265625\n",
      "Epoch, Loss: 4 ,  4.023380279541016\n",
      "Epoch, Loss: 4 ,  3.9541308879852295\n",
      "Epoch, Loss: 4 ,  4.007129669189453\n",
      "Epoch, Loss: 4 ,  4.081024646759033\n",
      "Epoch, Loss: 4 ,  4.003619194030762\n",
      "Epoch, Loss: 4 ,  4.0087666511535645\n",
      "Epoch, Loss: 4 ,  4.021867275238037\n",
      "Epoch, Loss: 4 ,  4.013208389282227\n",
      "Epoch, Loss: 4 ,  3.983935832977295\n",
      "Epoch, Loss: 4 ,  4.006891250610352\n",
      "Epoch, Loss: 4 ,  4.0252861976623535\n",
      "Epoch, Loss: 4 ,  4.027204513549805\n",
      "Epoch, Loss: 4 ,  3.9806418418884277\n",
      "Epoch, Loss: 4 ,  4.012026786804199\n",
      "Epoch, Loss: 4 ,  3.9839229583740234\n",
      "Epoch, Loss: 4 ,  4.005186557769775\n",
      "Epoch, Loss: 4 ,  3.983290433883667\n",
      "epoch: 4\n",
      "Training: batch_loss: 4.009, Accuracy: 1.532\n"
     ]
    }
   ],
   "source": [
    "#training = 0\n",
    "samples_tr = 0\n",
    "correct_tr = 0\n",
    "act_model.train()\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs): #training loop\n",
    "    batch_losses = []\n",
    "\n",
    "    act_sample_tr = 0\n",
    "    act_sample_ts = 0\n",
    "    for msAcc_tr, msGyro_tr, Acc_tr, Grav_tr, jinAcc_tr, jinGyro_tr, liAcc_tr, Mag_tr, Gyro_tr, labels_tr in train_loader:\n",
    "            # print(\"Dimensions of each sensor modality:\")\n",
    "            # print(f\"msAcc_tr: {msAcc_tr.shape}\")\n",
    "            # print(f\"msGyro_tr: {msGyro_tr.shape}\")\n",
    "            # print(f\"bbh_labels_tr: {labels_tr.shape}\")\n",
    "\n",
    "            \n",
    "            #labels_tr  = labels_tr.to(device)\n",
    "            \n",
    "            \n",
    "            optimizer_act.zero_grad()\n",
    "\n",
    "            labels_predicted = act_model(msAcc_tr, msGyro_tr, Acc_tr, Grav_tr, jinAcc_tr, jinGyro_tr, liAcc_tr, Mag_tr, Gyro_tr)\n",
    "            #labels_predicted = labels_predicted.flatten()\n",
    "            labels_tr = labels_tr.type(torch.LongTensor)\n",
    "\n",
    "            _, predicted_tr = torch.max(labels_predicted,1)\n",
    "            #print(\"predicted_tr.shape\", predicted_tr.shape)   \n",
    "\n",
    "            samples_tr += labels_tr.size(0)\n",
    "            correct_tr += (predicted_tr == labels_tr).sum().item()\n",
    "            loss = loss_fn(labels_predicted, labels_tr)\n",
    "            loss = loss.unsqueeze(0)\n",
    "            epoch_loss = loss.item()\n",
    "            print(\"Epoch, Loss:\" , epoch,\", \", epoch_loss)\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer_act.step()\n",
    "\n",
    "    act_loss = sum(batch_losses)/len(batch_losses)\n",
    "        #average_loss[1].append(bbh_loss)\n",
    "    accr = 100.0 * correct_tr / samples_tr\n",
    "\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"Training: batch_loss: {act_loss:.3f}, Accuracy: {accr:.3f}\")\n",
    "    #print(f\"Training: batch_loss: {act_loss:.3f}, {state_correct_tr}/{state_samples_tr}, state_acc: {state_acc:.3f}%,  bbh_loss: {bbh_loss:.3f}, {bbh_correct_tr}/{bbh_samples_tr} , bbh_acc: {bbh_acc:.3f}%\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "-mnyqLmqcmY4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.1\n"
     ]
    }
   ],
   "source": [
    "#F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(labels_tr, predicted_tr,average=\"macro\")\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "zuAeq-4Clu6v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_tr.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(precision_score(labels_tr, predicted_tr,average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
